# -*- coding: utf-8 -*-
"""Facial Emotion Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCT8OOoFXnx6zkN7n_YB6Yxm--YkzZBK
"""

import cv2

!pip install deepface

img=cv2.imread("/content/633322d33a072576bda1011d813cd3ab.jpg")

import matplotlib.pyplot as plt

plt.imshow(img)

plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

import warnings
warnings.filterwarnings("ignore")

!pip install DeepFace

from deepface import DeepFace

import warnings
warnings.filterwarnings("ignore")

predictions=DeepFace.analyze(img)

predictions

print(predictions[0]['dominant_emotion'])

faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')

font=cv2.FONT_HERSHEY_SIMPLEX
cv2.putText(img,predictions[0]['dominant_emotion'],(0,100),font,1,(0,0,225),2,cv2.LINE_4)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

import cv2
from deepface import DeepFace
face_values=cv2.CascadeClassifier(cv2.data.haarcascades+'/content/haarcascade_frontalface_default (2).xml')
video=cv2.VideoCapture(0)
while video.isOpened():
  _,frame=video.read()
  gray_img=cv2.cvColor(frame,cv2.COLOR_BGR2GRAY)
  face=face_values.detectMultiScale(gray_img,scaleFactor=1.1,minNeighbor=5)
  for x , y,w,h in face:
    img=cv2.rectangle(frame,(x,y),(x+y,y+h),(0,225,225),1)
    try:
      analyze=DeepFace.analyze(frame,actions=['emotion'])
      print(analyze['dominant+emoyion'])
    except:
      print("no face")
      cv2.imshow('video',frame)
      if key==cv2.waitKey(1):
        if key==ord('v'):
          break
video.release()